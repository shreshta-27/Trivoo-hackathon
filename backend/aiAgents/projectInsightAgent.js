import { StateGraph } from "@langchain/langgraph";import { ChatGoogleGenerativeAI } from "@langchain/google-genai";import { HumanMessage, SystemMessage } from "@langchain/core/messages";import { PROJECT_INSIGHT_SYSTEM_PROMPT, HEALTH_CHANGE_PROMPT, MAINTENANCE_FEEDBACK_PROMPT, SIMULATION_ANALYSIS_PROMPT } from "./prompts/projectInsightPrompts.js";const getMockInsightFallback = (type) => {    const mocks = [        {            title: "Climate Resilience Detected",            summary: "Project maintaining health despite rising temperatures.",            detail: "Genetic resilience or microclimate factors are buffering the 2°C heat spike.",            sentiment: "positive",            recommendation: "Continue current irrigation protocol."        },        {            title: "Yield Projection Updated",            summary: "Biomass accumulation rate exceeds baseline by 5%.",            detail: "Favorable rainfall distribution has accelerated early-stage growth.",            sentiment: "positive",            recommendation: "Plan for early harvest feasibility study."        },        {            title: "Minor Stress Indicators",            summary: "Localized moisture stress in North-East sector.",            detail: "Satellite IR imagery shows potential irrigation blockage.",            sentiment: "neutral",            recommendation: "Inspect irrigation lines in Sector 4."        }    ];    const random = mocks[Math.floor(Math.random() * mocks.length)];    console.warn("\n⚠️ [AI FALLBACK] Insight Agent failed. Serving Robust Mock Data.");    return {        ...random,        aiMetadata: { model: "fallback-sim-v1", confidence: 0.85, processingTime: 12 }    };};const initializeLLM = () => {    return new ChatGoogleGenerativeAI({        model: process.env.AI_MODEL || "gemini-pro",        temperature: parseFloat(process.env.AI_TEMPERATURE) || 0.3,        apiKey: process.env.GEMINI_API_KEY    });};class InsightState {    constructor() {        this.projectContext = null;        this.environmentalDelta = null;        this.analysisType = null;        this.llmResponse = null;        this.finalInsight = null;        this.errors = [];    }}const projectContextNode = async (state) => {    try {        if (!state.projectContext) {            state.errors.push("Missing project context");        }        return state;    } catch (error) {        state.errors.push(`Context error: ${error.message}`);        return state;    }};const environmentalDeltaNode = async (state) => {    try {        const { currentEnv, previousEnv } = state.projectContext;        state.environmentalDelta = {            rainfallChange: currentEnv.rainfall - (previousEnv?.rainfall || currentEnv.rainfall),            temperatureChange: currentEnv.temperature.max - (previousEnv?.temperature?.max || currentEnv.temperature.max),            newRisks: currentEnv.activeRisks.filter(r =>                !previousEnv?.activeRisks?.some(pr => pr.type === r.type)            )        };        return state;    } catch (error) {        state.errors.push(`Delta calculation error: ${error.message}`);        return state;    }};const riskInterpretationNode = async (state) => {    try {        const { project, currentEnv } = state.projectContext;        const llm = initializeLLM();        let prompt;        if (state.analysisType === 'health_change') {            prompt = HEALTH_CHANGE_PROMPT                .replace('{projectName}', project.name)                .replace('{treeType}', project.treeType)                .replace('{plantationSize}', project.plantationSize)                .replace('{previousScore}', state.projectContext.previousHealth || project.healthScore)                .replace('{currentScore}', project.healthScore)                .replace('{change}', project.healthScore - (state.projectContext.previousHealth || project.healthScore))                .replace('{rainfall}', currentEnv.rainfall)                .replace('{rainfallChange}', state.environmentalDelta.rainfallChange)                .replace('{tempMin}', currentEnv.temperature.min)                .replace('{tempMax}', currentEnv.temperature.max)                .replace('{activeRisks}', currentEnv.activeRisks.map(r => r.type).join(', ') || 'None')                .replace('{maintenanceHistory}', state.projectContext.recentMaintenance || 'No recent maintenance');        } else if (state.analysisType === 'maintenance_feedback') {            const action = state.projectContext.action;            prompt = MAINTENANCE_FEEDBACK_PROMPT                .replace('{projectName}', project.name)                .replace('{actionType}', action.actionType)                .replace('{actionDescription}', action.description)                .replace('{performedAt}', action.createdAt)                .replace('{wasRecommended}', action.wasRecommended)                .replace('{timingStatus}', action.timingStatus)                .replace('{healthBefore}', action.impact?.healthScoreBefore || 'N/A')                .replace('{healthAfter}', action.impact?.healthScoreAfter || 'N/A')                .replace('{recommendation}', state.projectContext.recommendation || 'No specific recommendation');        } else if (state.analysisType === 'simulation') {            const sim = state.projectContext.simulation;            prompt = SIMULATION_ANALYSIS_PROMPT                .replace('{projectName}', project.name)                .replace('{scenarioType}', sim.scenarioType)                .replace('{duration}', sim.duration)                .replace('{rainfallChange}', sim.parameters.rainfallChange || 0)                .replace('{temperatureChange}', sim.parameters.temperatureChange || 0)                .replace('{maintenanceFrequency}', sim.parameters.maintenanceFrequency || 'normal')                .replace('{currentHealth}', project.healthScore)                .replace('{activeRisks}', project.activeRisks.map(r => r.type).join(', ') || 'None');        }        const startTime = Date.now();        const messages = [            new SystemMessage(PROJECT_INSIGHT_SYSTEM_PROMPT),            new HumanMessage(prompt)        ];        const response = await llm.invoke(messages);        const processingTime = Date.now() - startTime;        let content = response.content;        if (content.includes('```json')) {            content = content.split('```json')[1].split('```')[0].trim();        } else if (content.includes('```')) {            content = content.split('```')[1].split('```')[0].trim();        }        state.llmResponse = {            ...JSON.parse(content),            processingTime        };        return state;    } catch (error) {        state.errors.push(`LLM error: ${error.message}`);        return state;    }};const insightGenerationNode = async (state) => {    try {        if (!state.llmResponse) {            state.errors.push("No LLM response available");            return state;        }        state.finalInsight = {            ...state.llmResponse,            aiMetadata: {                model: process.env.AI_MODEL || "gemini-pro",                temperature: parseFloat(process.env.AI_TEMPERATURE) || 0.3,                processingTime: state.llmResponse.processingTime,                confidence: state.llmResponse.confidence || 0.8            }        };        return state;    } catch (error) {        state.errors.push(`Insight generation error: ${error.message}`);        return state;    }};const buildInsightWorkflow = () => {    const workflow = new StateGraph({        channels: {            projectContext: null,            environmentalDelta: null,            analysisType: null,            llmResponse: null,            finalInsight: null,            errors: []        }    });    workflow.addNode("projectContext", projectContextNode);    workflow.addNode("environmentalDelta", environmentalDeltaNode);    workflow.addNode("riskInterpretation", riskInterpretationNode);    workflow.addNode("insightGeneration", insightGenerationNode);    workflow.addEdge("__start__", "projectContext");    workflow.addEdge("projectContext", "environmentalDelta");    workflow.addEdge("environmentalDelta", "riskInterpretation");    workflow.addEdge("riskInterpretation", "insightGeneration");    workflow.addEdge("insightGeneration", "__end__");    return workflow.compile();};export const generateProjectInsight = async (projectContext, analysisType) => {    const workflow = buildInsightWorkflow();    const initialState = new InsightState();    initialState.projectContext = projectContext;    initialState.analysisType = analysisType;    try {        const result = await workflow.invoke(initialState);        if (result.errors && result.errors.length > 0) {            throw new Error(`Workflow errors: ${result.errors.join(', ')}`);        }        return result.finalInsight;    } catch (error) {        console.error("Insight Workflow Failed:", error.message);        return getMockInsightFallback(analysisType);    }};export default {    generateProjectInsight,    buildInsightWorkflow};